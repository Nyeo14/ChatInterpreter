{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\wizard king\n",
      "[nltk_data]     rabbit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (36, 3075)\n",
      "['0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '1', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '1', '1', '0', '1']\n",
      "Number of training examples:  28\n",
      "Number of testing examples:  8\n",
      "Vocabulary size:  3075\n",
      "\n",
      "Training a model with 28 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 62.50\n",
      " AUC value: 87.50\n",
      "Positive weight rank  1 : \n",
      "---> 105 , and its weight is:  0.2724456019920526\n",
      "Positive weight rank  2 : \n",
      "---> range , and its weight is:  0.21300869706647468\n",
      "Positive weight rank  3 : \n",
      "---> t90gg , and its weight is:  0.20769098440372152\n",
      "Negative weight rank  1 : \n",
      "---> yes , and its weight is:  -0.13036995661602316\n",
      "Negative weight rank  2 : \n",
      "---> t90salute , and its weight is:  -0.07706047088675366\n",
      "Negative weight rank  3 : \n",
      "---> mbl , and its weight is:  -0.07067521780826595\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (52, 15330)\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0']\n",
      "Number of training examples:  41\n",
      "Number of testing examples:  11\n",
      "Vocabulary size:  15330\n",
      "\n",
      "Training a model with 41 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 63.64\n",
      " AUC value: 58.33\n",
      "Positive weight rank  1 : \n",
      "---> gg , and its weight is:  0.08329724921125241\n",
      "Positive weight rank  2 : \n",
      "---> t90rekt t90rekt , and its weight is:  0.08010506726418105\n",
      "Positive weight rank  3 : \n",
      "---> 1111111111111 , and its weight is:  0.0744098251302533\n",
      "Negative weight rank  1 : \n",
      "---> lul , and its weight is:  -0.15203991095026745\n",
      "Negative weight rank  2 : \n",
      "---> pogchamp , and its weight is:  -0.1397352653802406\n",
      "Negative weight rank  3 : \n",
      "---> pogchamp pogchamp , and its weight is:  -0.11911486928234645\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (44, 5235)\n",
      "['0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0']\n",
      "Number of training examples:  35\n",
      "Number of testing examples:  9\n",
      "Vocabulary size:  5235\n",
      "\n",
      "Training a model with 35 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 77.78\n",
      " AUC value: 57.14\n",
      "Positive weight rank  1 : \n",
      "---> alive , and its weight is:  0.17447494325346485\n",
      "Positive weight rank  2 : \n",
      "---> t90lel , and its weight is:  0.13973043917660216\n",
      "Positive weight rank  3 : \n",
      "---> revolution , and its weight is:  0.13022052338519052\n",
      "Negative weight rank  1 : \n",
      "---> t90pog , and its weight is:  -0.10282488704180785\n",
      "Negative weight rank  2 : \n",
      "---> music , and its weight is:  -0.10118516350830171\n",
      "Negative weight rank  3 : \n",
      "---> lul , and its weight is:  -0.08783344913739873\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (34, 7351)\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0']\n",
      "Number of training examples:  27\n",
      "Number of testing examples:  7\n",
      "Vocabulary size:  7351\n",
      "\n",
      "Training a model with 27 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 42.86\n",
      " AUC value: 60.00\n",
      "Positive weight rank  1 : \n",
      "---> lul , and its weight is:  0.28685600282050805\n",
      "Positive weight rank  2 : \n",
      "---> clutch , and its weight is:  0.2725170380003715\n",
      "Positive weight rank  3 : \n",
      "---> kekw , and its weight is:  0.1965748007632715\n",
      "Negative weight rank  1 : \n",
      "---> thats , and its weight is:  -0.08329428885400922\n",
      "Negative weight rank  2 : \n",
      "---> thats thats , and its weight is:  -0.07323207140093747\n",
      "Negative weight rank  3 : \n",
      "---> bet , and its weight is:  -0.06834141089709318\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (43, 8929)\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '1']\n",
      "Number of training examples:  34\n",
      "Number of testing examples:  9\n",
      "Vocabulary size:  8929\n",
      "\n",
      "Training a model with 34 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 100.00\n",
      " AUC value: 100.00\n",
      "Positive weight rank  1 : \n",
      "---> teoslaugh , and its weight is:  0.22132547673951736\n",
      "Positive weight rank  2 : \n",
      "---> clutch , and its weight is:  0.21756787517536788\n",
      "Positive weight rank  3 : \n",
      "---> teoslaugh teoslaugh , and its weight is:  0.17048584407713832\n",
      "Negative weight rank  1 : \n",
      "---> teo , and its weight is:  -0.1515884019458214\n",
      "Negative weight rank  2 : \n",
      "---> poll , and its weight is:  -0.1202838323503743\n",
      "Negative weight rank  3 : \n",
      "---> katielstare , and its weight is:  -0.09639374703892413\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (41, 7878)\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '1', '1', '1', '0', '1', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0']\n",
      "Number of training examples:  32\n",
      "Number of testing examples:  9\n",
      "Vocabulary size:  7878\n",
      "\n",
      "Training a model with 32 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 77.78\n",
      " AUC value: 100.00\n",
      "Positive weight rank  1 : \n",
      "---> pogchamp , and its weight is:  0.24987050583965117\n",
      "Positive weight rank  2 : \n",
      "---> lul , and its weight is:  0.21768815022205312\n",
      "Positive weight rank  3 : \n",
      "---> nice , and its weight is:  0.1972422746508843\n",
      "Negative weight rank  1 : \n",
      "---> siege , and its weight is:  -0.24172868511906417\n",
      "Negative weight rank  2 : \n",
      "---> teo , and its weight is:  -0.1464864983665712\n",
      "Negative weight rank  3 : \n",
      "---> yes , and its weight is:  -0.12460430820085225\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (45, 7304)\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '1', '0', '0', '1', '0', '0', '0', '1', '0', '1', '0']\n",
      "Number of training examples:  36\n",
      "Number of testing examples:  9\n",
      "Vocabulary size:  7304\n",
      "\n",
      "Training a model with 36 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 100.00\n",
      " AUC value: 100.00\n",
      "Positive weight rank  1 : \n",
      "---> lul , and its weight is:  0.33193524233069827\n",
      "Positive weight rank  2 : \n",
      "---> pog , and its weight is:  0.2605629895290717\n",
      "Positive weight rank  3 : \n",
      "---> pata , and its weight is:  0.21217611019358773\n",
      "Negative weight rank  1 : \n",
      "---> like , and its weight is:  -0.12656748116735247\n",
      "Negative weight rank  2 : \n",
      "---> thanks , and its weight is:  -0.09673479753186864\n",
      "Negative weight rank  3 : \n",
      "---> money , and its weight is:  -0.07952314720476755\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (57, 8956)\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '1', '0', '1', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "Number of training examples:  45\n",
      "Number of testing examples:  12\n",
      "Vocabulary size:  8956\n",
      "\n",
      "Training a model with 45 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 83.33\n",
      " AUC value: 90.00\n",
      "Positive weight rank  1 : \n",
      "---> gg , and its weight is:  0.2760253995259141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive weight rank  2 : \n",
      "---> lul , and its weight is:  0.26694624021691915\n",
      "Positive weight rank  3 : \n",
      "---> lul lul , and its weight is:  0.18261346875228127\n",
      "Negative weight rank  1 : \n",
      "---> teosonemore , and its weight is:  -0.10992652416758907\n",
      "Negative weight rank  2 : \n",
      "---> just , and its weight is:  -0.10188377959681601\n",
      "Negative weight rank  3 : \n",
      "---> teo , and its weight is:  -0.09203342998155406\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (43, 7727)\n",
      "['0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '1', '1', '0', '1', '0', '1', '0', '1', '1', '0', '0', '0', '1', '1', '1', '0', '0', '1', '0', '0']\n",
      "Number of training examples:  34\n",
      "Number of testing examples:  9\n",
      "Vocabulary size:  7727\n",
      "\n",
      "Training a model with 34 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 77.78\n",
      " AUC value: 95.00\n",
      "Positive weight rank  1 : \n",
      "---> shit , and its weight is:  0.19810286080590356\n",
      "Positive weight rank  2 : \n",
      "---> lul , and its weight is:  0.1873091151685315\n",
      "Positive weight rank  3 : \n",
      "---> holy , and its weight is:  0.18009063372986686\n",
      "Negative weight rank  1 : \n",
      "---> teoshype , and its weight is:  -0.09132485453582406\n",
      "Negative weight rank  2 : \n",
      "---> dont , and its weight is:  -0.08140549590086477\n",
      "Negative weight rank  3 : \n",
      "---> teoslaugh teoslaugh , and its weight is:  -0.08020884273744511\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (44, 8383)\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "Number of training examples:  35\n",
      "Number of testing examples:  9\n",
      "Vocabulary size:  8383\n",
      "\n",
      "Training a model with 35 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 88.89\n",
      " AUC value: 100.00\n",
      "Positive weight rank  1 : \n",
      "---> teosevil , and its weight is:  0.22298840235608217\n",
      "Positive weight rank  2 : \n",
      "---> teosew , and its weight is:  0.18934156166716598\n",
      "Positive weight rank  3 : \n",
      "---> lul , and its weight is:  0.1857530357063455\n",
      "Negative weight rank  1 : \n",
      "---> yes , and its weight is:  -0.11212571224000066\n",
      "Negative weight rank  2 : \n",
      "---> dead , and its weight is:  -0.09264097176822021\n",
      "Negative weight rank  3 : \n",
      "---> teo , and its weight is:  -0.09198857858017827\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (41, 6614)\n",
      "['1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0']\n",
      "Number of training examples:  32\n",
      "Number of testing examples:  9\n",
      "Vocabulary size:  6614\n",
      "\n",
      "Training a model with 32 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 88.89\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8d9cedbd7167>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-8d9cedbd7167>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_bow_from_reviews\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                 \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogistic_classification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[0mmost_significant_terms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-8d9cedbd7167>\u001b[0m in \u001b[0;36mlogistic_classification\u001b[1;34m(X, Y, test_fraction)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtest_accuracy\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'.2f'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mclass_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mtest_auc_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_probabilities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' AUC value:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtest_auc_score\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'.2f'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[0;32m    388\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         return _average_binary_score(partial(_binary_roc_auc_score,\n\u001b[0m\u001b[0;32m    391\u001b[0m                                              max_fpr=max_fpr),\n\u001b[0;32m    392\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[1;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;34m\"\"\"Binary roc auc score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[0;32m    224\u001b[0m                          \"is not defined in that case.\")\n\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import nltk \n",
    "from nltk import word_tokenize\n",
    "import simplejson as json\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import * \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn import metrics \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import Utilities\n",
    "import Tokenizer_kit\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# nltk.download('stopwords') is needed\n",
    "# the following functions are from HW1, with little modification.\n",
    "# \n",
    "\n",
    "def parts_of_speech(s):\n",
    "\ttokens = word_tokenize(s)\n",
    "\ttokens_and_tags = nltk.pos_tag(tokens)\n",
    "\tn = 0\n",
    "\ttemp = set()\n",
    "\tfor item in tokens_and_tags:\n",
    "\t\tif (not item[1] in temp):\n",
    "\t\t\ttemp.add(item[1])\n",
    "\t\t\tn += 1\n",
    "\tprint(\" the total number of tokens is \" + str(n))\n",
    "\ttags = [ item[1] for item in tokens_and_tags ]\n",
    "\ttag_counts = nltk.FreqDist(tags)\n",
    "\tsorted_tag_counts = tag_counts.most_common()\n",
    "\tfor item in sorted_tag_counts:\n",
    "\t\ttag_percent = 100 * item[1]/n\n",
    "\t\tp = '{0:.2f}'.format(tag_percent)\n",
    "\t\tprint('Tag:',item[0],'\\t   Percentage of tokens = ', p )\n",
    "\treturn(tokens_and_tags)\n",
    "\n",
    "def create_bow_from_reviews(clips):\n",
    "\ttext = []\n",
    "\tY = []\n",
    "\tlengths = []\n",
    "\tprint('\\nExtracting tokens from each review.....(can be slow for a large number of reviews)......')   \n",
    "\tfor clip in clips:\n",
    "\t\treview = Tokenizer_kit.Concatenate_str_list(clip.chats)\n",
    "\t\tstars = clip.get_label_binary()\n",
    "\t\tif (stars == -1):\n",
    "\t\t\tstars = 1\n",
    "\t\tif (stars == 1):\n",
    "\t\t\ttext.append(review)\n",
    "\t\t\tY.append('1')\n",
    "\t\tif (stars == 0):\n",
    "\t\t\ttext.append(review)   \n",
    "\t\t\tY.append('0')\n",
    "\tvectorizer = CountVectorizer(ngram_range = (1, 2), stop_words = 'english', min_df = 0.01)\n",
    "\tprint(\"show vectorizer: \", vectorizer)\n",
    "\tX = vectorizer.fit_transform(text)\n",
    "\tprint('Data shape: ', X.shape)\n",
    "\treturn X, Y, vectorizer\n",
    "    \n",
    "def logistic_classification(X, Y, test_fraction):\n",
    "\tX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_fraction, random_state=42)\n",
    "\tprint('Number of training examples: ', X_train.shape[0])\n",
    "\tprint('Number of testing examples: ', X_test.shape[0])   \n",
    "\tprint('Vocabulary size: ', X_train.shape[1])\n",
    "\tclassifier = linear_model.LogisticRegression(penalty = 'l2', fit_intercept = True)\n",
    "\tprint('\\nTraining a model with', X_train.shape[0], 'examples.....')\n",
    "\tclassifier.fit(X_train, Y_train)\n",
    "\ttrain_predictions = classifier.predict(X_train)\n",
    "\ttrain_accuracy = classifier.score(X_train, Y_train)\n",
    "\tprint('\\nTraining:')\n",
    "\tprint(' accuracy:',format( 100*train_accuracy , '.2f'))\n",
    "\tprint('\\nTesting: ')\n",
    "\ttest_predictions = classifier.predict(X_test)\n",
    "\ttest_accuracy = classifier.score(X_test, Y_test)\n",
    "\tprint(' accuracy:', format( 100*test_accuracy , '.2f') )\n",
    "\tclass_probabilities = classifier.predict_proba(X_test)\n",
    "\ttest_auc_score = sklearn.metrics.roc_auc_score(Y_test, class_probabilities[:,1])\n",
    "\tprint(' AUC value:', format( 100*test_auc_score , '.2f') )\n",
    "\treturn(classifier)\n",
    "\n",
    "def most_significant_terms(classifier, vectorizer, K):\n",
    "\tcount = 0\n",
    "\ttopK_pos_weights = set()\n",
    "\ttopK_pos_terms = set()\n",
    "\twhile(count < K):\n",
    "\t\tmax = -1\n",
    "\t\ttemp_count = 0\n",
    "\t\ttemp_term = \"null indicator, if the proper word is not found\"\n",
    "\t\tfor weight in classifier.coef_[0]:\n",
    "\t\t\tif (weight > 0 and weight > max and not weight in topK_pos_weights):\n",
    "\t\t\t\tmax = weight\n",
    "\t\t\t\ttemp_term = vectorizer.get_feature_names()[temp_count]\n",
    "\t\t\ttemp_count += 1\n",
    "\t\tif (not max == -1):\n",
    "\t\t\ttopK_pos_weights.add(max)\n",
    "\t\t\ttopK_pos_terms.add(temp_term)\n",
    "\t\t\tprint(\"Positive weight rank \", str(count + 1), \": \")\n",
    "\t\t\tprint(\"--->\", temp_term, \", and its weight is: \", str(max))\n",
    "\t\tcount += 1\n",
    "\tcount = 0\n",
    "\ttopK_neg_weights = set()\n",
    "\ttopK_neg_terms = set()\n",
    "\twhile(count < K):\n",
    "\t\tmin = 1\n",
    "\t\ttemp_count = 0\n",
    "\t\ttemp_term = \"null indicator, if the proper word is not found\"\n",
    "\t\tfor weight in classifier.coef_[0]:\n",
    "\t\t\tif (weight < 0 and weight < min and not weight in topK_neg_weights):\n",
    "\t\t\t\tmin = weight\n",
    "\t\t\t\ttemp_term = vectorizer.get_feature_names()[temp_count]\n",
    "\t\t\ttemp_count += 1\n",
    "\t\tif (not min == 1):\n",
    "\t\t\ttopK_neg_weights.add(min)\n",
    "\t\t\ttopK_neg_terms.add(temp_term)\n",
    "\t\t\tprint(\"Negative weight rank \", str(count + 1), \": \")\n",
    "\t\t\tprint(\"--->\", temp_term, \", and its weight is: \", str(min))\n",
    "\t\tcount += 1\n",
    "\treturn(topK_pos_weights, topK_neg_weights, topK_pos_terms, topK_neg_terms)\n",
    "\n",
    "def main():\n",
    "\tclip_list = []\n",
    "\tfor filename in os.listdir(\"labeled_clip_data\"):\n",
    "\t\tthe_file = open(\"labeled_clip_data/\" + filename, 'rb')\n",
    "\t\tthe_pkl = pickle.load(the_file)\n",
    "\t\tfor clip in the_pkl:\n",
    "\t\t\tclip_list.append(clip)\n",
    "\txx, yy, vect = create_bow_from_reviews(clip_list)\n",
    "\tprint(yy)\n",
    "\tclassifier = logistic_classification(xx, yy, 0.2)\n",
    "\tmost_significant_terms(classifier, vect, 3)\n",
    "\treturn\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a path to the pickle file that storing input stringclip_data/wardell[6]_labeled.pkl\n",
      "\n",
      "Extracting tokens from each review.....(can be slow for a large number of reviews)......\n",
      "show vectorizer:  CountVectorizer(min_df=0.01, ngram_range=(1, 2), stop_words='english')\n",
      "Data shape:  (52, 6075)\n",
      "['0', '1', '0', '0', '1', '1', '1', '1', '1', '0', '1', '1', '1', '1', '1', '0', '1', '1', '0', '0', '1', '1', '1', '1', '0', '0', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '1', '1', '1', '1', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "Number of training examples:  41\n",
      "Number of testing examples:  11\n",
      "Vocabulary size:  6075\n",
      "\n",
      "Training a model with 41 examples.....\n",
      "\n",
      "Training:\n",
      " accuracy: 100.00\n",
      "\n",
      "Testing: \n",
      " accuracy: 100.00\n",
      " AUC value: 100.00\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
