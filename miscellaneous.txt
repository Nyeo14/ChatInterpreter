This txt file is just for us to jog down any things we find during any part of development. 
For visual easiness in reading, I think we put new things at the end of this file (instead of in the beginning like in to_do txt) 


Feb 7: 
Duo Chen: 
> Notification chats are ignored by option, but if someone send a sub-message with chat-inducing content (such as a birthday), 
  chat will increase in speed. The specific classification may depend on our manual bias. I put it as "other". 
  Someone else may put it as "special topic". This point can be brought up in project report. 

> Twitch has this functino of betting with channel points. For now, treat those points as arbitrary currencies that 
  does not have monetary value. Bets can be "will this game be a win", or such. At the end of a bet, chat typically speeds up. 
  The classification depends on people, I put it on "other". 

> There are parts where the streamer meets a hacker in game. 
  Some chat's reactions are very similar to amusement at first, and then they mostly talk about it. 
  This also depend on person, but I put them as amusement because the reaction in the beginning is close to amusement. 

> Some classifications are really rare, such as disappointment and shock. 
  From my clips up to this point, I have about one in disappointment and none in shock. 
  But of course, such thing depends on manual labeling bias and characteristics of the streamer. 



Feb 8: 
Duo Chen: 
> category of clips does depend on type of streams, I added in new horror game vods and there is an increase in shock 
  class clips. 

> many clips has chat turning from one reaction to another within a time-span of two minutes, 
  such as from shock/scared to amusement.  

> a lot of noise in chats, mostly new viewer joining in, or people with irrelevant topics. 

Nate: 
> Different parameter specifications in clipping create data-inconsistency in manual processing 



Feb 9: 
JingTian Li: 
> Some streamers grew a chat community that has minimal reaction. Or their reaction is merely formality
  or majorly topic oriented. 

> Games are usually vocabularily distinct 


Feb 10: 
Nate, Duo Chen:
> some words in word2vec are completely messed up, with most similar word being irrelevant
  some of those words can be calibrated by decreasing model complexity, so we are likely overfitting 

> words from word2vec shows difference across streamers. Mixing streamers will give a more universal estimate on 
  average chat community, but will introduce strange noise to specific words. 


Feb 14: 
Duo Chen: 
> names as words usually have associations with words of emotions. It maybe a general representation of audience's 
  inner image of that person. For example, some names are closer to "lol" and some other are closer to "nice". 

> we found one emote that differentiate in capitalization, one is haHAA, the other is HAhaa 


Feb 16: 
Jing Tian: 
> in testing, there can be unseen vocabs not in training set. 


Feb 20: 
Duo Chen: 
> The annoying thing is that because of lack of data sets, learner greatly differ based on the training test split 
> Different streamers requires very different parameters, one need a hidden layer of 90, the other need a hidden layer of 3


Feb 21: 
Duo Chen: 
> RNN best result is 86.9% in testing with default of 77% accuracy 
> processing chat is also different depending on the chat community the streamer built up. 
> best params was: 
  > chat window 20,
  > overlap 3, 
  > n iter: 400 
  > hidden size: 90 
  > learning rate: 0.002
  > test ratio: 0.2 


  Feb 23: 
  Duo Chen: 
  > most of the mislabeled clips contains a lot of noise, 
  > for example, one of them has about 200-ish chats, but the manual classification is determined by a small block of lol inside 
  > the "disappointment" class is mislabeled, probably due to low number in training sample 
  > some other misclassifications are manual error, where rnn did a good job but human labeling is wrong. 